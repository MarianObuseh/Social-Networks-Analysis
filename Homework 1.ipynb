{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "import wikipedia\n",
    "\n",
    "# Specify name of the starting pages\n",
    "seed1 = \"Aqualung\".title()\n",
    "seed2 = \"Ian Anderson\".title()\n",
    "\n",
    "\n",
    "# Keep track of pages to process; we'll only do 2 layers,\n",
    "# process links as a BFS\n",
    "toDo_lst1 = [(0, seed1)]\n",
    "toDo_lst2 = [(0, seed2)]\n",
    "\n",
    "toDo_set1 = set(seed1)\n",
    "toDo_set2 = set(seed2)\n",
    "\n",
    "done_set1 = set()\n",
    "done_set2 = set()\n",
    "\n",
    "# Create two directed graphs\n",
    "F = nx.DiGraph()\n",
    "G = nx.DiGraph()\n",
    "\n",
    "layer1, page1 = toDo_lst1[0]\n",
    "layer2, page2 = toDo_lst2[0]\n",
    "    \n",
    "    \n",
    "count1 = 0\n",
    "\n",
    "while layer1 < 2:\n",
    "    del toDo_lst1[0]\n",
    "    done1 = done_set1.add(page1)\n",
    "    print(layer1, page1)\n",
    "    count1 = count1 + 1\n",
    "    if (count1 > 50):\n",
    "        break\n",
    "    try:\n",
    "            # Download the selected page\n",
    "        wiki1 = wikipedia.page(page1)\n",
    "    except:\n",
    "        layer1, page1 = toDo_lst1[0]\n",
    "        print(\"Could not load\", page1)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    for link in wiki1.links:\n",
    "        link = link.title()\n",
    "        if link not in toDo_set1 and link not in done_set1 and len(done_set1) < 50:\n",
    "            toDo_lst1.append((layer1+1, link))\n",
    "            toDo_set1.add(link)\n",
    "        F.add_edge(page1, link)\n",
    "\n",
    "    layer1, page1 = toDo_lst1[0]\n",
    "\n",
    "\n",
    "count2 = 0\n",
    "\n",
    "while layer2 < 2:\n",
    "    del toDo_lst2[0]\n",
    "    done2 = done_set2.add(page2)\n",
    "    print(layer2, page2)\n",
    "    count2 = count2 + 1\n",
    "    if (count2 > 50):\n",
    "        break\n",
    "    try:\n",
    "            # Download the selected page\n",
    "        wiki2 = wikipedia.page(page2)\n",
    "    except:\n",
    "        layer2, page2 = toDo_lst2[0]\n",
    "        print(\"Could not load\", page2)\n",
    "        continue\n",
    "\n",
    "    for link in wiki2.links:\n",
    "        link = link.title()\n",
    "        if link not in toDo_set2 and link not in done_set2 and len(done_set2) < 50:\n",
    "            toDo_lst2.append((layer2+1, link))\n",
    "            toDo_set2.add(link)\n",
    "        G.add_edge(page2, link)\n",
    "\n",
    "    layer2, page2 = toDo_lst2[0]\n",
    "\n",
    "print(\"The Aqualung graph has {} nodes, {} edges\". format(len(F),nx.number_of_edges(F)))\n",
    "print(\"The Ian Anderson graph has {} nodes, {} edges\". format(len(G),nx.number_of_edges(G)))\n",
    "\n",
    "\n",
    "# the following will get rid of some of \"self loops\" in both graphs\n",
    "F.remove_edges_from(nx.selfloop_edges(F))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "# F and G are both gigantic graphs. I make smaller subgraphs by only including nodes that have degree >= 2\n",
    "core1 = [node for node, deg in dict(F.degree()).items() if deg >= 2]\n",
    "H = nx.subgraph(F, core1)\n",
    "\n",
    "core2 = [node for node, deg in dict(G.degree()).items() if deg >= 2]\n",
    "I = nx.subgraph(G, core2)\n",
    "\n",
    "\n",
    "print(\"The new Aqualung graph has {} nodes, {} edges\".format(len(H), nx.number_of_edges(H)))\n",
    "print(\"The new Ian Anderson graph has {} nodes, {} edges\".format(len(I), nx.number_of_edges(I)))\n",
    "\n",
    "# Display the smaller graph for Aqualung\n",
    "pos = nx.spring_layout(H)\n",
    "plt.figure(figsize=(100,100))\n",
    "nx.draw_networkx(H, pos=pos, with_labels=True)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display the smaller graph for Ian Anderson\n",
    "pos = nx.spring_layout(I)\n",
    "plt.figure(figsize=(100,100))\n",
    "nx.draw_networkx(I, pos=pos, with_labels=True)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Display a list of subjects sorted by in-degree\n",
    "top_indegree = sorted(dict(G.in_degree()).items(),\n",
    "                      reverse=True, key=itemgetter(1))[:100]\n",
    "print(\"\\n\".join(map(lambda t: \"{} {}\".format(*reversed(t)), top_indegree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant library\n",
    "from numpy import array\n",
    "from itertools import product\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simrank_similarity(G, source=None, target=None, importance_factor=0.9, max_iterations=100, tolerance=1e-4):  \n",
    "    prevsim = None  \n",
    "    newsim = {u: {v: 1 if u == v else 0 for v in G} for u in G}  \n",
    "    avg_sim = lambda s: sum(newsim[w][x] for (w, x) in s) / len(s) if s else 0.0  \n",
    "    sim = lambda u, v: importance_factor * avg_sim(list(product(G[u], G[v]))) \n",
    "    \n",
    "    for _ in range(max_iterations):    \n",
    "        if prevsim and _is_close(prevsim, newsim, tolerance):      \n",
    "            break    \n",
    "        prevsim = newsim    \n",
    "        newsim = {u: {v: sim(u, v) if u is not v else 1 for v in newsim[u]} for u in newsim}  \n",
    "    \n",
    "    if source is not None and target is not None:    \n",
    "        return newsim[source][target]  \n",
    "    if source is not None:    \n",
    "        return newsim[source]  \n",
    "    return newsim\n",
    "        \n",
    "def _is_close(d1, d2, atolerance=0, rtolerance=0): \n",
    "    if not isinstance(d1, dict) and not isinstance(d2, dict):\n",
    "        return abs(d1 - d2) <= atolerance + rtolerance * abs(d2)  \n",
    "    return all(all(_is_close(d1[u][v], d2[u][v]) for v in d1[u]) for u in d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the aqualung graph\n",
    "sim1 = simrank_similarity(H)\n",
    "sim_nodes1 = [[sim1[u][v] for v in sorted(sim1[u])] for u in sorted(sim1)]\n",
    "sim_array1 = array(sim_nodes1)\n",
    "\n",
    "nodeList1 = list(H.nodes)\n",
    "n1 = len(nodeList1)\n",
    "threshold1 = 0.01\n",
    "for i in range(n1):\n",
    "    for j in range(n1):\n",
    "        if ((sim_array1[i][j] >= threshold1) and (i != j)):\n",
    "            print(\"(\",nodeList1[i], \",\", nodeList1[j], '): ', sim_array1[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the Ian Anderson graph\n",
    "sim2 = simrank_similarity(I)\n",
    "sim_nodes2 = [[sim2[u][v] for v in sorted(sim2[u])] for u in sorted(sim2)]\n",
    "sim_array2 = array(sim_nodes2)\n",
    "\n",
    "nodeList2 = list(I.nodes)\n",
    "n2 = len(nodeList2)\n",
    "threshold2 = 0.01\n",
    "for i in range(n2):\n",
    "    for j in range(n2):\n",
    "        if ((sim_array2[i][j] >= threshold2) and (i != j)):\n",
    "            print(\"(\",nodeList2[i], \",\", nodeList2[j], '): ', sim_array2[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = H.copy()\n",
    "\n",
    "J.remove_nodes_from(n for n in H if n in I)\n",
    "# K = nx.difference(J, I)\n",
    "\n",
    "remove1 = [node for node,degree in dict(J.degree()).items() if degree == 0]\n",
    "J.remove_nodes_from(remove1)\n",
    "print(nx.info(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = H.copy()\n",
    "L.remove_nodes_from(n for n in H if n not in I)\n",
    "\n",
    "remove2 = [node for node,degree in dict(L.degree()).items() if degree == 0]\n",
    "L.remove_nodes_from(remove2)\n",
    "print(nx.info(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
